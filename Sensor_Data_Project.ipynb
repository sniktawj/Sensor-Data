{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3349ad0c",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: center; color:blue\"> ISAT 341: Machine Learning and Data Science </h3>\n",
    "\n",
    "<h3 style = \"text-align: center; color:green\"> Project: Machine Learning Confidential Sensor Data </h3>\n",
    "\n",
    "<img src = \"images/machine_learning.jpg\" width=200; height=250; align= center>\n",
    "\n",
    "<h3 style = \"text-align: center; color:red\"> Working with <em>real-world</em> datasets </h3>\n",
    "\n",
    "### Objectives\n",
    "\n",
    "To demonstrate the ability to complete an end-to-end data science / machine learning project using real-world data by following and\n",
    "implementing the main machine learning checklist steps that lead to a solution, namely:\n",
    "* Frame the problem and look at the big picture.\n",
    "* Get the data.\n",
    "* Explore the data to gain insights.\n",
    "* Prepare the data to expose the underlying data patterns to Machine Learning algorithms.\n",
    "* Explore many different models and short-list the best ones.\n",
    "* Fine-tune your models and combine them into a great solution.\n",
    "* Present your solution.\n",
    "* Launch, monitor, and maintain your system\n",
    "\n",
    "<h3 style = \"text-align: left; color:purple\"> Frame the Problem </h3>\n",
    "\n",
    "<img src = \"images/sensor_array.jpg\" width=200; height=250; align= center>\n",
    "\n",
    "### Sensor Data\n",
    "\n",
    "The data source as well as the exact nature of the data is confidential. Each data instance contains 12 real-valued input attributes. Each input\n",
    "attribute represents a sensor designed to detect the presence of one of two groups of substances. As an alternative, the sensor readings may\n",
    "represent a 'false alarm'.\n",
    "* Substance 1 is represented by the value 'one' in the class attribute column.\n",
    "* Substance 2 is represented by the value 'two' in the class attribute column.\n",
    "* A false alarm is represented by the value 'three' in the class attribute column.\n",
    "\n",
    "The problem is framed as a **supervised learning** problem: Predict the class of a substance from sensor data using the given measurements in the dataset.\n",
    "\n",
    "<h3 style = \"text-align: Center; color:purple\"> Project Analysis Starts Here! </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7221bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abe0fb",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: left; color:green\"> Exploratory Data Analysis </h3>\n",
    "\n",
    "### 1) TO DO: Use Pandas to load your data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f49875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.473</td>\n",
       "      <td>2.311</td>\n",
       "      <td>3.179</td>\n",
       "      <td>2.666</td>\n",
       "      <td>0.27950</td>\n",
       "      <td>0.27710</td>\n",
       "      <td>0.22340</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.1110</td>\n",
       "      <td>4.712</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460</td>\n",
       "      <td>2.377</td>\n",
       "      <td>3.214</td>\n",
       "      <td>2.920</td>\n",
       "      <td>0.25270</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>1.213</td>\n",
       "      <td>1.0270</td>\n",
       "      <td>5.463</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552</td>\n",
       "      <td>2.164</td>\n",
       "      <td>3.064</td>\n",
       "      <td>2.745</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.19290</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>5.332</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.605</td>\n",
       "      <td>2.228</td>\n",
       "      <td>3.149</td>\n",
       "      <td>2.834</td>\n",
       "      <td>0.29170</td>\n",
       "      <td>0.36130</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>1.144</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>4.829</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.534</td>\n",
       "      <td>2.114</td>\n",
       "      <td>3.309</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.25020</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.17700</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>1.254</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>5.734</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.796</td>\n",
       "      <td>2.262</td>\n",
       "      <td>3.180</td>\n",
       "      <td>2.888</td>\n",
       "      <td>0.29660</td>\n",
       "      <td>0.14770</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>-9999.0000</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>4.861</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.566</td>\n",
       "      <td>2.323</td>\n",
       "      <td>3.469</td>\n",
       "      <td>2.711</td>\n",
       "      <td>0.24170</td>\n",
       "      <td>0.05371</td>\n",
       "      <td>0.21120</td>\n",
       "      <td>-0.02686</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>4.780</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.425</td>\n",
       "      <td>2.152</td>\n",
       "      <td>3.287</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.29910</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>1.271</td>\n",
       "      <td>1.1150</td>\n",
       "      <td>5.662</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.595</td>\n",
       "      <td>2.271</td>\n",
       "      <td>3.323</td>\n",
       "      <td>2.743</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>5.145</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.628</td>\n",
       "      <td>2.211</td>\n",
       "      <td>3.176</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.27830</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>5.613</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0    1.473    2.311    3.179    2.666  0.27950  0.27710  0.22340  0.18550   \n",
       "1    1.460    2.377    3.214    2.920  0.25270  0.30640  0.02563  0.19650   \n",
       "2    1.552    2.164    3.064    2.745  0.28200  0.21000  0.17210  0.19290   \n",
       "3    1.605    2.228    3.149    2.834  0.29170  0.36130  0.20870  0.12940   \n",
       "4    1.534    2.114    3.309    2.976  0.21000  0.25020  0.22580  0.17700   \n",
       "5    1.796    2.262    3.180    2.888  0.29660  0.14770  0.16240  0.28200   \n",
       "6    1.566    2.323    3.469    2.711  0.24170  0.05371  0.21120 -0.02686   \n",
       "7    1.425    2.152    3.287    2.781  0.29910  0.20750  0.10380  0.11470   \n",
       "8    1.595    2.271    3.323    2.743  0.17330  0.19650  0.16850  0.05859   \n",
       "9    1.628    2.211    3.176    2.710  0.08423  0.18920  0.27830  0.16850   \n",
       "\n",
       "     Input 9  Input 10  Input 11  Input 12 class  \n",
       "0     0.2539     1.138    1.1110     4.712   one  \n",
       "1     0.3027     1.213    1.0270     5.463   one  \n",
       "2     0.2100     1.221    1.0580     5.332   one  \n",
       "3     0.2734     1.144    1.0620     4.829   one  \n",
       "4     0.2039     1.254    1.1120     5.734   one  \n",
       "5 -9999.0000     1.172    1.0300     4.861   one  \n",
       "6     0.2197     1.158    0.9924     4.780   one  \n",
       "7     0.2698     1.271    1.1150     5.662   one  \n",
       "8     0.2051     1.290    1.0330     5.145   one  \n",
       "9     0.3491     1.155    1.0080     5.613   one  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Sensor_Data_Confidential_341Project_DataSet5.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1876e",
   "metadata": {},
   "source": [
    "### 2) TO DO: Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabad678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-102.944836</td>\n",
       "      <td>-109.711795</td>\n",
       "      <td>-111.319884</td>\n",
       "      <td>-67.994856</td>\n",
       "      <td>-124.949039</td>\n",
       "      <td>-105.066162</td>\n",
       "      <td>-81.658039</td>\n",
       "      <td>-125.587986</td>\n",
       "      <td>-100.835192</td>\n",
       "      <td>-74.740051</td>\n",
       "      <td>-85.312925</td>\n",
       "      <td>-78.599944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1027.427211</td>\n",
       "      <td>1050.057089</td>\n",
       "      <td>1072.729741</td>\n",
       "      <td>849.911071</td>\n",
       "      <td>1115.540299</td>\n",
       "      <td>1027.206775</td>\n",
       "      <td>903.995215</td>\n",
       "      <td>1115.467928</td>\n",
       "      <td>1003.772889</td>\n",
       "      <td>877.403031</td>\n",
       "      <td>930.088695</td>\n",
       "      <td>904.281076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.058500</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>4.848250</td>\n",
       "      <td>3.998250</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>0.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.082000</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>5.336000</td>\n",
       "      <td>5.041000</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>1.996000</td>\n",
       "      <td>1.285500</td>\n",
       "      <td>4.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.504000</td>\n",
       "      <td>2.354250</td>\n",
       "      <td>5.591250</td>\n",
       "      <td>5.642750</td>\n",
       "      <td>1.400750</td>\n",
       "      <td>2.159000</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>1.234250</td>\n",
       "      <td>4.974000</td>\n",
       "      <td>1.865250</td>\n",
       "      <td>5.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.105000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>5.944000</td>\n",
       "      <td>6.013000</td>\n",
       "      <td>2.754000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>1.199000</td>\n",
       "      <td>2.561000</td>\n",
       "      <td>5.312000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1      Input 2      Input 3      Input 4      Input 5  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -102.944836  -109.711795  -111.319884   -67.994856  -124.949039   \n",
       "std    1027.427211  1050.057089  1072.729741   849.911071  1115.540299   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       3.058500     0.817600     4.848250     3.998250     0.462600   \n",
       "50%       4.082000     1.353000     5.336000     5.041000     0.806300   \n",
       "75%       4.504000     2.354250     5.591250     5.642750     1.400750   \n",
       "max       5.105000     4.675000     5.944000     6.013000     2.754000   \n",
       "\n",
       "           Input 6      Input 7      Input 8      Input 9     Input 10  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -105.066162   -81.658039  -125.587986  -100.835192   -74.740051   \n",
       "std    1027.206775   903.995215  1115.467928  1003.772889   877.403031   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       0.649400     0.308800     0.188000     0.423600     1.379000   \n",
       "50%       1.634500     0.565200     0.302700     0.694600     1.996000   \n",
       "75%       2.159000     0.959800     0.491900     1.234250     4.974000   \n",
       "max       3.638000     2.446000     1.199000     2.561000     5.312000   \n",
       "\n",
       "          Input 11     Input 12  \n",
       "count  2064.000000  2064.000000  \n",
       "mean    -85.312925   -78.599944  \n",
       "std     930.088695   904.281076  \n",
       "min   -9999.000000 -9999.000000  \n",
       "25%       1.089000     0.789800  \n",
       "50%       1.285500     4.915000  \n",
       "75%       1.865250     5.403000  \n",
       "max       5.640000    20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329f060",
   "metadata": {},
   "source": [
    "### 3) TO DO: Display the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6c1e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae19ac9",
   "metadata": {},
   "source": [
    "### 4) TO DO: Drop the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fea705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First replace any value of -9999 to numpy's, nan type. \n",
    "df = df.replace(-9999, np.nan)\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27273cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of data in dataframe after cleansing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1110c",
   "metadata": {},
   "source": [
    "### 5) TO DO: Use pandas correlation method to find the two features (inputs) with the highest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a38fb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.corr of       Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0       1.473    2.311    3.179    2.666   0.2795   0.2771  0.22340  0.18550   \n",
       "1       1.460    2.377    3.214    2.920   0.2527   0.3064  0.02563  0.19650   \n",
       "2       1.552    2.164    3.064    2.745   0.2820   0.2100  0.17210  0.19290   \n",
       "3       1.605    2.228    3.149    2.834   0.2917   0.3613  0.20870  0.12940   \n",
       "4       1.534    2.114    3.309    2.976   0.2100   0.2502  0.22580  0.17700   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2059    3.682    1.301    4.939    4.453   0.4895   0.7922  0.23190  0.05005   \n",
       "2060    3.412    1.293    4.949    4.199   0.4578   0.9521  0.21360  0.23070   \n",
       "2061    3.640    1.284    5.111    4.460   0.5786   0.8020  0.26980  0.31740   \n",
       "2062    3.746    1.261    5.049    4.885   0.5835   1.1470  0.32350  0.23070   \n",
       "2063    3.959    1.108    5.422    4.835   0.5579   1.3230  0.51510  0.21000   \n",
       "\n",
       "      Input 9  Input 10  Input 11  Input 12 class  \n",
       "0      0.2539     1.138     1.111     4.712   one  \n",
       "1      0.3027     1.213     1.027     5.463   one  \n",
       "2      0.2100     1.221     1.058     5.332   one  \n",
       "3      0.2734     1.144     1.062     4.829   one  \n",
       "4      0.2039     1.254     1.112     5.734   one  \n",
       "...       ...       ...       ...       ...   ...  \n",
       "2059   0.3687     1.478     1.174     5.125   two  \n",
       "2060   0.4578     1.526     1.167     5.433   two  \n",
       "2061   0.4309     1.460     1.118     4.867   two  \n",
       "2062   0.4614     1.482     1.128     5.627   two  \n",
       "2063   0.5737     1.595     1.244     5.623   two  \n",
       "\n",
       "[1826 rows x 13 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f15bb-2b01-43bc-8af0-0cf6fbf0b834",
   "metadata": {},
   "source": [
    "Inputs 10 and ll are the most highly correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b243f8",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: Left; color:green\"> Data Visualization </h3>\n",
    "\n",
    "\n",
    "### 6) TO DO: Plot bar charts using pandas dataframe (plot the mean value of the sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d5ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean values are: \n",
      "Input 1     3.680058\n",
      "Input 2     1.727913\n",
      "Input 3     5.009482\n",
      "Input 4     4.709107\n",
      "Input 5     1.015576\n",
      "Input 6     1.525255\n",
      "Input 7     0.700818\n",
      "Input 8     0.372550\n",
      "Input 9     0.904062\n",
      "Input 10    2.779109\n",
      "Input 11    1.886693\n",
      "Input 12    3.772419\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get column names \n",
    "columns = df.columns.tolist()\n",
    "\n",
    "#exclude last column(class)\n",
    "features = len(columns)-1\n",
    "columns = columns[:features]\n",
    "\n",
    "#get and print the mean values for all sensors\n",
    "print('The mean values are: \\n{}'.format(df.mean(numeric_only=True)))\n",
    "\n",
    "#store mean vlues\n",
    "mean_values = df[:].mean(numeric_only=True)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(columns,mean_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c3847",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: Left; color:green\"> Data Preprocessing </h3>\n",
    "\n",
    "### 7) TO DO: Create Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd731712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the features\n",
    "y = df['class']\n",
    "X = df[['Input 1',\t'Input 2','Input 3','Input 4','Input 5','Input 6','Input 7','Input 8','Input 9','Input 10','Input 11', 'Input 12']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dc913",
   "metadata": {},
   "source": [
    "### 8) TO DO: Convert the features dataframe to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c474f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.473, 2.311, 3.179, ..., 1.138, 1.111, 4.712],\n",
       "       [1.46 , 2.377, 3.214, ..., 1.213, 1.027, 5.463],\n",
       "       [1.552, 2.164, 3.064, ..., 1.221, 1.058, 5.332],\n",
       "       ...,\n",
       "       [3.64 , 1.284, 5.111, ..., 1.46 , 1.118, 4.867],\n",
       "       [3.746, 1.261, 5.049, ..., 1.482, 1.128, 5.627],\n",
       "       [3.959, 1.108, 5.422, ..., 1.595, 1.244, 5.623]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.to_numpy()\n",
    "X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2647d2",
   "metadata": {},
   "source": [
    "### 9) TO DO: Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84621d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LabelEncoder.fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#encode class labels\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit(y)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m### NOT REALLY SURE WHY THIS DOESNT WORK, FUCKKKK ME\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print the categorical class labels we encoded\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_encoded)\n",
      "\u001b[0;31mTypeError\u001b[0m: LabelEncoder.fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "#import label encoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#instantiate integer encoder\n",
    "label_encoder = LabelEncoder\n",
    "\n",
    "#encode class labels\n",
    "y_encoded = label_encoder.fit(y)\n",
    "\n",
    "### NOT REALLY SURE WHY THIS DOESNT WORK, FUCKKKK ME\n",
    "\n",
    "#print the categorical class labels we encoded\n",
    "print(y_encoded)\n",
    "#print a few encoded values using slice\n",
    "\n",
    "#print the shape of the encoded classes\n",
    "print('encoded shape:',y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588fe25",
   "metadata": {},
   "source": [
    "### 10) TO DO: Split the data into Training and Testing Sets\n",
    "\n",
    "Scikit learn contains a function called the **train_test_split** function that will randomly shuffle the dataset and then splits it into two datasets: a\n",
    "**training set** used to build the model and a **test set** to assess and evaluate how well the model works on unseen data (also called outof=sample data).\n",
    "\n",
    "### *Using 80%/20% split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35614a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#test_size= 0.20 means the test consists of 20% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a19413",
   "metadata": {},
   "source": [
    "### 11) TO DO: Look at the shape of the data (rows and columns) after splitting it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6dea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c84a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8fce4e",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: left; color:green\"> Scale the Data </h3>\n",
    "<h3 style = \"text-align: left; color:red\"> IMPORTANT: Standardizing the features:</h3>\n",
    "\n",
    "Standardization of datasets (feature scaling) is a common requirement for many machine learning and optimization algorithms implemented in\n",
    "scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data, i.e., Gaussian\n",
    "with zero mean and unit variance\n",
    "\n",
    "### 12) TO DO: Using the StandarScaler from Scikit-learn to transform (scale) our feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScalar()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std =sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab3a60",
   "metadata": {},
   "source": [
    "**A comment on what the above code does**\n",
    "\n",
    "* Using the preceding code, we loaded the StandardScaler class from the preprocessing module and initialized a new StandardScaler objectthat we assigned to the variable sc.\n",
    "* Using the fit method, StandardScaler estimated the parameters μ (sample mean) and (standard deviation) for each feature dimensionfrom the training data.\n",
    "* By calling the transform method, we then standardized the training data using those estimated parameters μ and .\n",
    "* Note that we used the same scaling parameters to standardize the test set so that both the values in the training and test dataset are comparable to each other\n",
    "\n",
    "<h3 style = \"text-align: left; color:green\"> Model Building </h3>\n",
    "\n",
    "**Training multiple Machine Learning models during same session.** \n",
    "1. K-Nearest Neighbor (with K=10, K=50, K=200)\n",
    "2. Logistic Regression\n",
    "3. Linear Support Vector Classifier\n",
    "\n",
    "<h3 style = \"text-align: left; color:green\"> Build a KNN Classification Model for K = 10, 50 and 200 </h3>\n",
    "\n",
    "### 13) Build and train the actual machine learning model using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b21fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model selection process\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#pick K-nearest neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "k=knn.n_neighbors\n",
    "print(\"Model's acccuracy on Test set for K = {0} is :{1:0.2f}\\n\".format(k,knn.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9965f1f",
   "metadata": {},
   "source": [
    "### Predicting class-membership probabilites\n",
    "\n",
    "Scikit-Learn has a method that allows prediction of class member probabilities.\n",
    "\n",
    "The probability that training examples belong to a certain class can be computed using the **predict_proba** method. For example, we canpredict the probabilities of the first three samples in the test set as follows (NOTE: X_test_std[:3. :] means get the first 3 rows and the associated columns from the test dataset X_test):\n",
    "\n",
    "classifier.predict_proba(X_test_std[:3, :]) where classifier is either K-NN or Logistic Regression\n",
    "\n",
    "In the cells below, your must predict the **class-membership probabilities** for each specified **SINGLE ROW OF DATA**\n",
    "\n",
    "Also, you should recall that the label encoding that we implemented earlier resulted in the mapping:\n",
    "\n",
    "**class membership label indices after encoding**\n",
    "0 = 'one' (the Substance is Substance 1)\n",
    "1 = 'three' (false alarm)\n",
    "2 = 'two' (The Substance is Substance 2)\n",
    "\n",
    "### 14) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 10** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c9d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30741aad",
   "metadata": {},
   "source": [
    "### 15) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 125** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178d8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d3f6c05",
   "metadata": {},
   "source": [
    "### 16) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 200** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5235f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23e198cd",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Build Logistic Regresion Model </h2>\n",
    "\n",
    "### 17) TO DO: scikit-learn Logistic Regression for this lab\n",
    "**Import and instantiate the *Logistic Regression* Model in SciKit-Learn is in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81acf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d80e0b",
   "metadata": {},
   "source": [
    "### 18) TO DO: Train the model by calling the model's fit function\n",
    "\n",
    "Now that the model has been instantiated (created) it still needs to be trained (fitted) to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2f228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff9fe5dc",
   "metadata": {},
   "source": [
    "### 19) TO DO: Evaluate the Logistic Regression Model\n",
    "Use the test set to create the model's predictions. Name the prediction vector **y_pred** as in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f3d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02e9a401",
   "metadata": {},
   "source": [
    "### 20) TO DO: Evaluate the Logistic Regression Model's Performance\n",
    "Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e83b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a1748f5",
   "metadata": {},
   "source": [
    "### Predicting class-membership probabilities using the Logistic Regression Model\n",
    "\n",
    "### 21) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 10** from the X_test_std data. Make sure your print statement uses a\n",
    "complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f366a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69487fbc",
   "metadata": {},
   "source": [
    "### 22) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 130** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e424d56",
   "metadata": {},
   "source": [
    "### 23) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 200** from the X_test_std data. Make sure your print statement uses a\n",
    "complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a255623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bd8331",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Build Linear Support Vector Classifier Model </h2>\n",
    "\n",
    "### 24) TO DO:scikit-learn Linear Support Vector Classifier for this lab\n",
    "\n",
    "**Import and instantiate the Linear Support Vector Classifier Model in SciKit-Learn is in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd66a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "593d9ed8",
   "metadata": {},
   "source": [
    "### 25) TO DO: Train the model by calling the model's fit function\n",
    "Now that the model has been instantiated (created) it still needs to be trained (fitted) to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87f900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d1ab2c2",
   "metadata": {},
   "source": [
    "### 26) TO DO: Evaluate the Linear Suport Vector Classifier Model\n",
    "Use the test set to create the model's predictions. Name the prediction vector **y_pred** as in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f526f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff42f54",
   "metadata": {},
   "source": [
    "### 27) TO DO: Evaluate the Linear Suport Vector Model's Performance\n",
    "Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b037f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78a17514",
   "metadata": {},
   "source": [
    "### 28) TO DO: Using the Predict Method of the Linear Suport Vector Model\n",
    "Use SciKit Learn's built-in *predict method* to test the model's predictive performance for the first row of data in X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b29b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19885d8",
   "metadata": {},
   "source": [
    "### 29) TO DO:Print the number of misclassifications using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0464fd",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Confusion Matrix </h2>\n",
    "\n",
    "Supervised learner models are designed to classify, estimate, and/or predict future outcome. For some applications the desire is to build models showing consistently high predictive accuracy.\n",
    "\n",
    "### Classification Correctness:\n",
    "\n",
    "Classification correctness is best calculated by presenting previously unseen data in the form of a test set to the model being evaluated. Test\n",
    "set model accuracy can be summarized in a table known as a confusion matrix. To illustrate, let’s suppose we have three possible classes: C1,\n",
    "C2, and C3. A generic confusion matrix for the three class case is shown in Table 1.\n",
    "\n",
    "* Values along the main diagonal give the total number of correct classifications for each class.\n",
    "  * For example, a value of 15 for C11 means that 15 class C1 test set instances were correctly classified.\n",
    "* Values other than those on the main diagonal represent classification errors.\n",
    "    * To illustrate, suppose C12 has the value 4. This means that four class C1 instances were incorrectly classified as belonging to class C2. The following three rules may be helpful in analyzing the information in a confusion matrix:\n",
    "\n",
    "### Rules for the Three-Class Confusion Matrix\n",
    "* Rule 1. Values along the main diagonal represent correct classifications. For the matrix in Table 1,the value C11 represents the total number of class C1 instances correctly classified by the model. A similar statement can be made for the values C22 and C33.\n",
    "* Rule 2. Values in row Ci represent those instances that belong to class Ci. For example, with i = 2,the instances associated with cells C21, C22, and C23 are all actually members of C2. To find the total number of C2 instances incorrectly classified as members of another class, we compute the sum of C21 and C23.\n",
    "* Rule 3. Values found in column Ci indicate those instances that have been classified as members of Ci. With i = 2,the instances associated with cells C12, C22, and C32 have been classified as members of class C2.To find the total number of instances incorrectly classified as members of class C2, we compute the sum of C12 and C32\n",
    "\n",
    "### 30) TO DO: Compute the Confusion Matrix for the Linear Suport Vector Model\n",
    "\n",
    "Use SciKit Learn's metrics module to compute the model's confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbfe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3237faac",
   "metadata": {},
   "source": [
    "### 31)TO DO: Classification Correctness\n",
    "Based on the output of your confusion matrix, what was the total number of correct classifications of Substance 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29a6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1bbf7d",
   "metadata": {},
   "source": [
    "### 32) TO DO: Compute the Classification report for Linear Suport Vector Model\n",
    "Use SciKit Learn's metrics module to compute the model's classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ab642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "941ad396",
   "metadata": {},
   "source": [
    "### 33) TO DO: Classification Report\n",
    "\n",
    "Based on the output of your classification report, out of all the times Substance 1 should have been predicted, what percentage of times was\n",
    "it correctly predicted?\n",
    "\n",
    "Which performance score did you use to evaluate the performance of the model(s) from the confusion matrix /classification report? (HINT: You\n",
    "may need to research the meaning and difference between precision, recall and f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d22668",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c1bbad",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Serialization </h2>\n",
    "\n",
    "<h3 style = \"text-align: left; color:purple\"> 34) TO DO: Model Persistence - Save/Load the trained classifier  </h3>\n",
    "\n",
    "To receive full credit for this part you must test the saved and re-loaded classifiers on an instance of “unknown” data and show that it correctly\n",
    "classifies the instance. It’s ok if you use an instance (sample) that is from the test set as the “unknown” data.\n",
    "\n",
    "<b style = \"text-align: left; color:purple\"> NOTE: Use either the Logistic Regression Model or the K-Nearest Neighbors Classifier for this part  </b>\n",
    "\n",
    "### Step1: Save the model\n",
    "\n",
    "**Pickle (serialize) and save the trained classifier to a folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a916b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb7a872",
   "metadata": {},
   "source": [
    "### Step 2: Load the saved model\n",
    "\n",
    "**Load the saved the trained classifier into memory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd1446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d6f873",
   "metadata": {},
   "source": [
    "### Step 3: Test the re-loaded model\n",
    "\n",
    "Use SciKit Learn's built-in predict method to test the re-loaded model on data from the row of data in X_test_std with index equal to six (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be442247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d0bf04",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "<h3 style = \"text-align:left; color: red\">BONUS (15 pts)</h3>\n",
    "\n",
    "It is **your choice** to do the bonus or not. It can only add points to your total course grade. It wont't hurt your grade if you chose NOT to do it.\n",
    "BUT, if you are going to attempt it, do it in the cells below (add cells as necessary). Follow the instructions for the notebook cells layout exactly\n",
    "as indicated in the bonus document or you may not receive credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a86a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dd3db58",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align:center; color: red\">End of Project</h3>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
