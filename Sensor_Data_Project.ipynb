{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3349ad0c",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: center; color:blue\"> ISAT 341: Machine Learning and Data Science </h3>\n",
    "\n",
    "<h3 style = \"text-align: center; color:green\"> Project: Machine Learning Confidential Sensor Data </h3>\n",
    "\n",
    "<img src = \"images/machine_learning.jpg\" width=200; height=250; align= center>\n",
    "\n",
    "<h3 style = \"text-align: center; color:red\"> Working with <em>real-world</em> datasets </h3>\n",
    "\n",
    "### Objectives\n",
    "\n",
    "To demonstrate the ability to complete an end-to-end data science / machine learning project using real-world data by following and\n",
    "implementing the main machine learning checklist steps that lead to a solution, namely:\n",
    "* Frame the problem and look at the big picture.\n",
    "* Get the data.\n",
    "* Explore the data to gain insights.\n",
    "* Prepare the data to expose the underlying data patterns to Machine Learning algorithms.\n",
    "* Explore many different models and short-list the best ones.\n",
    "* Fine-tune your models and combine them into a great solution.\n",
    "* Present your solution.\n",
    "* Launch, monitor, and maintain your system\n",
    "\n",
    "<h3 style = \"text-align: left; color:purple\"> Frame the Problem </h3>\n",
    "\n",
    "<img src = \"images/sensor_array.jpg\" width=200; height=250; align= center>\n",
    "\n",
    "### Sensor Data\n",
    "\n",
    "The data source as well as the exact nature of the data is confidential. Each data instance contains 12 real-valued input attributes. Each input\n",
    "attribute represents a sensor designed to detect the presence of one of two groups of substances. As an alternative, the sensor readings may\n",
    "represent a 'false alarm'.\n",
    "* Substance 1 is represented by the value 'one' in the class attribute column.\n",
    "* Substance 2 is represented by the value 'two' in the class attribute column.\n",
    "* A false alarm is represented by the value 'three' in the class attribute column.\n",
    "\n",
    "The problem is framed as a **supervised learning** problem: Predict the class of a substance from sensor data using the given measurements in the dataset.\n",
    "\n",
    "<h3 style = \"text-align: Center; color:purple\"> Project Analysis Starts Here! </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7221bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abe0fb",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: left; color:green\"> Exploratory Data Analysis </h3>\n",
    "\n",
    "### 1) TO DO: Use Pandas to load your data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f49875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.473</td>\n",
       "      <td>2.311</td>\n",
       "      <td>3.179</td>\n",
       "      <td>2.666</td>\n",
       "      <td>0.27950</td>\n",
       "      <td>0.27710</td>\n",
       "      <td>0.22340</td>\n",
       "      <td>0.18550</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>1.138</td>\n",
       "      <td>1.1110</td>\n",
       "      <td>4.712</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.460</td>\n",
       "      <td>2.377</td>\n",
       "      <td>3.214</td>\n",
       "      <td>2.920</td>\n",
       "      <td>0.25270</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>1.213</td>\n",
       "      <td>1.0270</td>\n",
       "      <td>5.463</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552</td>\n",
       "      <td>2.164</td>\n",
       "      <td>3.064</td>\n",
       "      <td>2.745</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.19290</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1.221</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>5.332</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.605</td>\n",
       "      <td>2.228</td>\n",
       "      <td>3.149</td>\n",
       "      <td>2.834</td>\n",
       "      <td>0.29170</td>\n",
       "      <td>0.36130</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.2734</td>\n",
       "      <td>1.144</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>4.829</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.534</td>\n",
       "      <td>2.114</td>\n",
       "      <td>3.309</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.25020</td>\n",
       "      <td>0.22580</td>\n",
       "      <td>0.17700</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>1.254</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>5.734</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.796</td>\n",
       "      <td>2.262</td>\n",
       "      <td>3.180</td>\n",
       "      <td>2.888</td>\n",
       "      <td>0.29660</td>\n",
       "      <td>0.14770</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>0.28200</td>\n",
       "      <td>-9999.0000</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>4.861</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.566</td>\n",
       "      <td>2.323</td>\n",
       "      <td>3.469</td>\n",
       "      <td>2.711</td>\n",
       "      <td>0.24170</td>\n",
       "      <td>0.05371</td>\n",
       "      <td>0.21120</td>\n",
       "      <td>-0.02686</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>4.780</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.425</td>\n",
       "      <td>2.152</td>\n",
       "      <td>3.287</td>\n",
       "      <td>2.781</td>\n",
       "      <td>0.29910</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>1.271</td>\n",
       "      <td>1.1150</td>\n",
       "      <td>5.662</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.595</td>\n",
       "      <td>2.271</td>\n",
       "      <td>3.323</td>\n",
       "      <td>2.743</td>\n",
       "      <td>0.17330</td>\n",
       "      <td>0.19650</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>5.145</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.628</td>\n",
       "      <td>2.211</td>\n",
       "      <td>3.176</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.27830</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>1.155</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>5.613</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0    1.473    2.311    3.179    2.666  0.27950  0.27710  0.22340  0.18550   \n",
       "1    1.460    2.377    3.214    2.920  0.25270  0.30640  0.02563  0.19650   \n",
       "2    1.552    2.164    3.064    2.745  0.28200  0.21000  0.17210  0.19290   \n",
       "3    1.605    2.228    3.149    2.834  0.29170  0.36130  0.20870  0.12940   \n",
       "4    1.534    2.114    3.309    2.976  0.21000  0.25020  0.22580  0.17700   \n",
       "5    1.796    2.262    3.180    2.888  0.29660  0.14770  0.16240  0.28200   \n",
       "6    1.566    2.323    3.469    2.711  0.24170  0.05371  0.21120 -0.02686   \n",
       "7    1.425    2.152    3.287    2.781  0.29910  0.20750  0.10380  0.11470   \n",
       "8    1.595    2.271    3.323    2.743  0.17330  0.19650  0.16850  0.05859   \n",
       "9    1.628    2.211    3.176    2.710  0.08423  0.18920  0.27830  0.16850   \n",
       "\n",
       "     Input 9  Input 10  Input 11  Input 12 class  \n",
       "0     0.2539     1.138    1.1110     4.712   one  \n",
       "1     0.3027     1.213    1.0270     5.463   one  \n",
       "2     0.2100     1.221    1.0580     5.332   one  \n",
       "3     0.2734     1.144    1.0620     4.829   one  \n",
       "4     0.2039     1.254    1.1120     5.734   one  \n",
       "5 -9999.0000     1.172    1.0300     4.861   one  \n",
       "6     0.2197     1.158    0.9924     4.780   one  \n",
       "7     0.2698     1.271    1.1150     5.662   one  \n",
       "8     0.2051     1.290    1.0330     5.145   one  \n",
       "9     0.3491     1.155    1.0080     5.613   one  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Sensor_Data_Confidential_341Project_DataSet5.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1876e",
   "metadata": {},
   "source": [
    "### 2) TO DO: Describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabad678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-102.944836</td>\n",
       "      <td>-109.711795</td>\n",
       "      <td>-111.319884</td>\n",
       "      <td>-67.994856</td>\n",
       "      <td>-124.949039</td>\n",
       "      <td>-105.066162</td>\n",
       "      <td>-81.658039</td>\n",
       "      <td>-125.587986</td>\n",
       "      <td>-100.835192</td>\n",
       "      <td>-74.740051</td>\n",
       "      <td>-85.312925</td>\n",
       "      <td>-78.599944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1027.427211</td>\n",
       "      <td>1050.057089</td>\n",
       "      <td>1072.729741</td>\n",
       "      <td>849.911071</td>\n",
       "      <td>1115.540299</td>\n",
       "      <td>1027.206775</td>\n",
       "      <td>903.995215</td>\n",
       "      <td>1115.467928</td>\n",
       "      <td>1003.772889</td>\n",
       "      <td>877.403031</td>\n",
       "      <td>930.088695</td>\n",
       "      <td>904.281076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.058500</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>4.848250</td>\n",
       "      <td>3.998250</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>0.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.082000</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>5.336000</td>\n",
       "      <td>5.041000</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>1.996000</td>\n",
       "      <td>1.285500</td>\n",
       "      <td>4.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.504000</td>\n",
       "      <td>2.354250</td>\n",
       "      <td>5.591250</td>\n",
       "      <td>5.642750</td>\n",
       "      <td>1.400750</td>\n",
       "      <td>2.159000</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>1.234250</td>\n",
       "      <td>4.974000</td>\n",
       "      <td>1.865250</td>\n",
       "      <td>5.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.105000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>5.944000</td>\n",
       "      <td>6.013000</td>\n",
       "      <td>2.754000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>1.199000</td>\n",
       "      <td>2.561000</td>\n",
       "      <td>5.312000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1      Input 2      Input 3      Input 4      Input 5  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -102.944836  -109.711795  -111.319884   -67.994856  -124.949039   \n",
       "std    1027.427211  1050.057089  1072.729741   849.911071  1115.540299   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       3.058500     0.817600     4.848250     3.998250     0.462600   \n",
       "50%       4.082000     1.353000     5.336000     5.041000     0.806300   \n",
       "75%       4.504000     2.354250     5.591250     5.642750     1.400750   \n",
       "max       5.105000     4.675000     5.944000     6.013000     2.754000   \n",
       "\n",
       "           Input 6      Input 7      Input 8      Input 9     Input 10  \\\n",
       "count  2064.000000  2064.000000  2064.000000  2064.000000  2064.000000   \n",
       "mean   -105.066162   -81.658039  -125.587986  -100.835192   -74.740051   \n",
       "std    1027.206775   903.995215  1115.467928  1003.772889   877.403031   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       0.649400     0.308800     0.188000     0.423600     1.379000   \n",
       "50%       1.634500     0.565200     0.302700     0.694600     1.996000   \n",
       "75%       2.159000     0.959800     0.491900     1.234250     4.974000   \n",
       "max       3.638000     2.446000     1.199000     2.561000     5.312000   \n",
       "\n",
       "          Input 11     Input 12  \n",
       "count  2064.000000  2064.000000  \n",
       "mean    -85.312925   -78.599944  \n",
       "std     930.088695   904.281076  \n",
       "min   -9999.000000 -9999.000000  \n",
       "25%       1.089000     0.789800  \n",
       "50%       1.285500     4.915000  \n",
       "75%       1.865250     5.403000  \n",
       "max       5.640000    20.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329f060",
   "metadata": {},
   "source": [
    "### 3) TO DO: Display the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6c1e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2064, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae19ac9",
   "metadata": {},
   "source": [
    "### 4) TO DO: Drop the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fea705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First replace any value of -9999 to numpy's, nan type. \n",
    "df = df.replace(-9999, np.nan)\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27273cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of data in dataframe after cleansing\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1110c",
   "metadata": {},
   "source": [
    "### 5) TO DO: Use pandas correlation method to find the two features (inputs) with the highest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a38fb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.corr of       Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0       1.473    2.311    3.179    2.666   0.2795   0.2771  0.22340  0.18550   \n",
       "1       1.460    2.377    3.214    2.920   0.2527   0.3064  0.02563  0.19650   \n",
       "2       1.552    2.164    3.064    2.745   0.2820   0.2100  0.17210  0.19290   \n",
       "3       1.605    2.228    3.149    2.834   0.2917   0.3613  0.20870  0.12940   \n",
       "4       1.534    2.114    3.309    2.976   0.2100   0.2502  0.22580  0.17700   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2059    3.682    1.301    4.939    4.453   0.4895   0.7922  0.23190  0.05005   \n",
       "2060    3.412    1.293    4.949    4.199   0.4578   0.9521  0.21360  0.23070   \n",
       "2061    3.640    1.284    5.111    4.460   0.5786   0.8020  0.26980  0.31740   \n",
       "2062    3.746    1.261    5.049    4.885   0.5835   1.1470  0.32350  0.23070   \n",
       "2063    3.959    1.108    5.422    4.835   0.5579   1.3230  0.51510  0.21000   \n",
       "\n",
       "      Input 9  Input 10  Input 11  Input 12 class  \n",
       "0      0.2539     1.138     1.111     4.712   one  \n",
       "1      0.3027     1.213     1.027     5.463   one  \n",
       "2      0.2100     1.221     1.058     5.332   one  \n",
       "3      0.2734     1.144     1.062     4.829   one  \n",
       "4      0.2039     1.254     1.112     5.734   one  \n",
       "...       ...       ...       ...       ...   ...  \n",
       "2059   0.3687     1.478     1.174     5.125   two  \n",
       "2060   0.4578     1.526     1.167     5.433   two  \n",
       "2061   0.4309     1.460     1.118     4.867   two  \n",
       "2062   0.4614     1.482     1.128     5.627   two  \n",
       "2063   0.5737     1.595     1.244     5.623   two  \n",
       "\n",
       "[1826 rows x 13 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f15bb-2b01-43bc-8af0-0cf6fbf0b834",
   "metadata": {},
   "source": [
    "Inputs 10 and ll are the most highly correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b243f8",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: Left; color:green\"> Data Visualization </h3>\n",
    "\n",
    "\n",
    "### 6) TO DO: Plot bar charts using pandas dataframe (plot the mean value of the sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d5ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean values are: \n",
      "Input 1     3.680058\n",
      "Input 2     1.727913\n",
      "Input 3     5.009482\n",
      "Input 4     4.709107\n",
      "Input 5     1.015576\n",
      "Input 6     1.525255\n",
      "Input 7     0.700818\n",
      "Input 8     0.372550\n",
      "Input 9     0.904062\n",
      "Input 10    2.779109\n",
      "Input 11    1.886693\n",
      "Input 12    3.772419\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get column names \n",
    "columns = df.columns.tolist()\n",
    "\n",
    "#exclude last column(class)\n",
    "features = len(columns)-1\n",
    "columns = columns[:features]\n",
    "\n",
    "#get and print the mean values for all sensors\n",
    "print('The mean values are: \\n{}'.format(df.mean(numeric_only=True)))\n",
    "\n",
    "#store mean vlues\n",
    "mean_values = df[:].mean(numeric_only=True)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(columns,mean_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c3847",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: Left; color:green\"> Data Preprocessing </h3>\n",
    "\n",
    "### 7) TO DO: Create Feature Matrix and Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd731712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the features\n",
    "y = df['class']\n",
    "X = df[['Input 1','Input 2','Input 3','Input 4','Input 5','Input 6','Input 7','Input 8','Input 9','Input 10','Input 11', 'Input 12']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dc913",
   "metadata": {},
   "source": [
    "### 8) TO DO: Convert the features dataframe to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c474f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.473, 2.311, 3.179, ..., 1.138, 1.111, 4.712],\n",
       "       [1.46 , 2.377, 3.214, ..., 1.213, 1.027, 5.463],\n",
       "       [1.552, 2.164, 3.064, ..., 1.221, 1.058, 5.332],\n",
       "       ...,\n",
       "       [3.64 , 1.284, 5.111, ..., 1.46 , 1.118, 4.867],\n",
       "       [3.746, 1.261, 5.049, ..., 1.482, 1.128, 5.627],\n",
       "       [3.959, 1.108, 5.422, ..., 1.595, 1.244, 5.623]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.to_numpy()\n",
    "X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2647d2",
   "metadata": {},
   "source": [
    "### 9) TO DO: Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84621d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       one\n",
      "1       one\n",
      "2       one\n",
      "3       one\n",
      "4       one\n",
      "       ... \n",
      "2059    two\n",
      "2060    two\n",
      "2061    two\n",
      "2062    two\n",
      "2063    two\n",
      "Name: class, Length: 1826, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#import label encoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#instantiate integer encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#encode class labels\n",
    "label_encoder.fit(y)\n",
    "\n",
    "#print the categorical class labels we encoded\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588fe25",
   "metadata": {},
   "source": [
    "### 10) TO DO: Split the data into Training and Testing Sets\n",
    "\n",
    "Scikit learn contains a function called the **train_test_split** function that will randomly shuffle the dataset and then splits it into two datasets: a\n",
    "**training set** used to build the model and a **test set** to assess and evaluate how well the model works on unseen data (also called outof=sample data).\n",
    "\n",
    "### *Using 80%/20% split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35614a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#test_size= 0.20 means the test consists of 20% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a19413",
   "metadata": {},
   "source": [
    "### 11) TO DO: Look at the shape of the data (rows and columns) after splitting it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b6dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train.shape: (1460, 12)\n",
      "y train.shape: (1460,)\n",
      "X test.shape: (366, 12)\n",
      "y test.shape: (366,)\n"
     ]
    }
   ],
   "source": [
    "#Displaying the dimensions of the training set\n",
    "print('X train.shape: {}'.format(X_train.shape))\n",
    "print('y train.shape: {}'.format(y_train.shape))\n",
    "#Displaying the dimensions of the test set\n",
    "print('X test.shape: {}'.format(X_test.shape))\n",
    "print('y test.shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fce4e",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align: left; color:green\"> Scale the Data </h3>\n",
    "<h3 style = \"text-align: left; color:red\"> IMPORTANT: Standardizing the features:</h3>\n",
    "\n",
    "Standardization of datasets (feature scaling) is a common requirement for many machine learning and optimization algorithms implemented in\n",
    "scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data, i.e., Gaussian\n",
    "with zero mean and unit variance\n",
    "\n",
    "### 12) TO DO: Using the StandarScaler from Scikit-learn to transform (scale) our feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca27554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std =scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab3a60",
   "metadata": {},
   "source": [
    "**A comment on what the above code does**\n",
    "\n",
    "* Using the preceding code, we loaded the StandardScaler class from the preprocessing module and initialized a new StandardScaler objectthat we assigned to the variable sc.\n",
    "* Using the fit method, StandardScaler estimated the parameters μ (sample mean) and (standard deviation) for each feature dimensionfrom the training data.\n",
    "* By calling the transform method, we then standardized the training data using those estimated parameters μ and .\n",
    "* Note that we used the same scaling parameters to standardize the test set so that both the values in the training and test dataset are comparable to each other\n",
    "\n",
    "<h3 style = \"text-align: left; color:green\"> Model Building </h3>\n",
    "\n",
    "**Training multiple Machine Learning models during same session.** \n",
    "1. K-Nearest Neighbor (with K=10, K=50, K=200)\n",
    "2. Logistic Regression\n",
    "3. Linear Support Vector Classifier\n",
    "\n",
    "<h3 style = \"text-align: left; color:green\"> Build a KNN Classification Model for K = 10, 50 and 200 </h3>\n",
    "\n",
    "### 13) Build and train the actual machine learning model using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b21fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's acccuracy on Test set for K = 10 is :0.98\n",
      "\n",
      "Model's acccuracy on Test set for K = 50 is :0.93\n",
      "\n",
      "Model's acccuracy on Test set for K = 200 is :0.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "numbers =[10,50,200]\n",
    "knn_objects = []\n",
    "#model selection process\n",
    "for numb in numbers:\n",
    "    knn = KNeighborsClassifier(n_neighbors=numb)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_objects.append(knn)\n",
    "    print(\"Model's acccuracy on Test set for K = {0} is :{1:0.2f}\\n\".format(numb,knn.score(X_test,y_test)))\n",
    "#pick K-nearest neighbors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9965f1f",
   "metadata": {},
   "source": [
    "### Predicting class-membership probabilites\n",
    "\n",
    "Scikit-Learn has a method that allows prediction of class member probabilities.\n",
    "\n",
    "The probability that training examples belong to a certain class can be computed using the **predict_proba** method. For example, we canpredict the probabilities of the first three samples in the test set as follows (NOTE: X_test_std[:3. :] means get the first 3 rows and the associated columns from the test dataset X_test):\n",
    "\n",
    "classifier.predict_proba(X_test_std[:3, :]) where classifier is either K-NN or Logistic Regression\n",
    "\n",
    "In the cells below, your must predict the **class-membership probabilities** for each specified **SINGLE ROW OF DATA**\n",
    "\n",
    "Also, you should recall that the label encoding that we implemented earlier resulted in the mapping:\n",
    "\n",
    "**class membership label indices after encoding**\n",
    "0 = 'one' (the Substance is Substance 1)\n",
    "1 = 'three' (false alarm)\n",
    "2 = 'two' (The Substance is Substance 2)\n",
    "\n",
    "### ***************************************************14) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 10** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47c9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted membership probabibility of the 10th row is: [[1. 0. 0.]]\n",
      "The actual class membership is: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'The predicted membership probabibility of the 10th row is: {knn_objects[0].predict_proba(X_test_std[9,:].reshape(1, -1))}')\n",
    "print(f'The actual class membership is: {y_test[10]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30741aad",
   "metadata": {},
   "source": [
    "### 15) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 125** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7178d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted membership probabibility of the 125th row is: [[0.98 0.   0.02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'The predicted membership probabibility of the 125th row is: {knn_objects[1].predict_proba(X_test_std[124,:].reshape(1, -1))}')\n",
    "#print(f'The actual class membership is: {y_test[124]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f6c05",
   "metadata": {},
   "source": [
    "### 16) TO DO:class-membership probability\n",
    "\n",
    "Predict the class membership probability by using the a row with **index = 200** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a5235f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted membership probabibility of the 200th row is: [[1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'The predicted membership probabibility of the 200th row is: {knn_objects[2].predict_proba(X_test_std[199,:].reshape(1, -1))}')\n",
    "#print(f'The actual class membership is: {y_test[200]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e198cd",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Build Logistic Regresion Model </h2>\n",
    "\n",
    "### 17) TO DO: scikit-learn Logistic Regression for this lab\n",
    "**Import and instantiate the *Logistic Regression* Model in SciKit-Learn is in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f81acf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiating the LinearRegression() mething\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver = 'newton-cg',\n",
    "                       multi_class = 'multinomial',\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d80e0b",
   "metadata": {},
   "source": [
    "### 18) TO DO: Train the model by calling the model's fit function\n",
    "\n",
    "Now that the model has been instantiated (created) it still needs to be trained (fitted) to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e2f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0,\n",
       "                   solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0,\n",
       "                   solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0,\n",
       "                   solver='newton-cg')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the model's fit function\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fe5dc",
   "metadata": {},
   "source": [
    "### 19) TO DO: Evaluate the Logistic Regression Model\n",
    "Use the test set to create the model's predictions. Name the prediction vector **y_pred** as in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7f3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set prediction: \n",
      " ['three' 'three' 'one' 'one' 'three' 'three' 'one' 'two' 'one' 'one' 'two'\n",
      " 'two' 'two' 'one' 'three' 'one' 'two' 'one' 'three' 'two' 'three' 'one'\n",
      " 'two' 'two' 'one' 'one' 'two' 'three' 'three' 'one' 'two' 'two' 'two'\n",
      " 'one' 'two' 'two' 'one' 'one' 'two' 'two' 'one' 'three' 'one' 'three'\n",
      " 'three' 'three' 'two' 'two' 'three' 'one' 'three' 'three' 'one' 'one'\n",
      " 'three' 'one' 'two' 'two' 'one' 'one' 'one' 'two' 'one' 'one' 'two' 'two'\n",
      " 'one' 'two' 'one' 'two' 'one' 'three' 'one' 'one' 'two' 'three' 'one'\n",
      " 'one' 'two' 'three' 'three' 'one' 'three' 'two' 'two' 'one' 'two' 'two'\n",
      " 'three' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'one' 'two' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'one' 'two' 'two' 'one' 'three' 'two' 'two'\n",
      " 'two' 'one' 'one' 'one' 'one' 'three' 'one' 'two' 'one' 'three' 'three'\n",
      " 'one' 'one' 'two' 'two' 'two' 'three' 'two' 'one' 'one' 'three' 'one'\n",
      " 'three' 'two' 'one' 'two' 'two' 'two' 'three' 'two' 'two' 'one' 'two'\n",
      " 'two' 'two' 'two' 'two' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'two' 'two' 'two' 'one' 'two' 'one' 'one' 'two' 'one' 'two' 'one' 'two'\n",
      " 'three' 'one' 'two' 'two' 'two' 'two' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'one' 'two' 'three' 'three' 'three' 'two' 'one' 'one' 'two' 'two' 'two'\n",
      " 'one' 'one' 'one' 'one' 'two' 'two' 'three' 'three' 'one' 'one' 'one'\n",
      " 'one' 'two' 'two' 'three' 'one' 'one' 'one' 'three' 'one' 'two' 'three'\n",
      " 'one' 'three' 'two' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'three' 'one' 'two' 'one' 'one' 'three' 'one' 'one' 'two' 'one' 'two'\n",
      " 'one' 'two' 'one' 'two' 'two' 'one' 'two' 'three' 'three' 'one' 'two'\n",
      " 'one' 'three' 'one' 'two' 'three' 'two' 'two' 'one' 'one' 'one' 'three'\n",
      " 'one' 'two' 'two' 'one' 'three' 'one' 'three' 'one' 'three' 'two' 'two'\n",
      " 'two' 'one' 'one' 'one' 'one' 'two' 'one' 'two' 'one' 'three' 'one'\n",
      " 'three' 'three' 'one' 'two' 'one' 'two' 'two' 'three' 'two' 'two' 'three'\n",
      " 'two' 'one' 'two' 'three' 'three' 'two' 'three' 'one' 'three' 'three'\n",
      " 'one' 'three' 'three' 'three' 'two' 'two' 'one' 'one' 'three' 'one' 'one'\n",
      " 'two' 'three' 'two' 'two' 'two' 'two' 'two' 'two' 'one' 'three' 'one'\n",
      " 'three' 'three' 'one' 'two' 'one' 'three' 'two' 'one' 'two' 'two' 'two'\n",
      " 'one' 'three' 'three' 'one' 'two' 'three' 'one' 'two' 'one' 'three' 'one'\n",
      " 'two' 'three' 'two' 'one' 'three' 'two' 'two' 'one' 'three' 'two' 'one'\n",
      " 'two' 'one' 'one' 'one' 'three' 'one' 'one' 'two' 'two' 'one' 'one']\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(\"Test set prediction: \\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9a401",
   "metadata": {},
   "source": [
    "### 20) TO DO: Evaluate the Logistic Regression Model's Performance\n",
    "Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d70e83b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values: \n",
      " 894     three\n",
      "889     three\n",
      "132       one\n",
      "357       one\n",
      "1001    three\n",
      "        ...  \n",
      "422       one\n",
      "815       two\n",
      "1923      two\n",
      "307       one\n",
      "253       one\n",
      "Name: class, Length: 366, dtype: object\n",
      "Test accuracy: \n",
      " 0.98\n",
      "Number of misclassified instances: \n",
      " 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Values: \\n {}\".format(y_test))\n",
    "print('Test accuracy: \\n {0:0.2f}'.format(lr.score(X_test,y_test)))\n",
    "misclassified = np.sum(y_test != y_pred)\n",
    "print(\"Number of misclassified instances: \\n {}\".format(misclassified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1748f5",
   "metadata": {},
   "source": [
    "### Predicting class-membership probabilities using the Logistic Regression Model\n",
    "\n",
    "### 21) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 10** from the X_test_std data. Make sure your print statement uses a\n",
    "complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f366a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, 3, None), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, 3, None), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lr\u001b[38;5;241m.\u001b[39mpredict_proba(X_test[:\u001b[38;5;241m3\u001b[39m, :])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3660\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m   3661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5737\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5735\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5736\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, 3, None), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "print('The predicted probablity for belonging to the class[class=0 class=1] are{0}'.format(lr.predict_proba(X_test[9,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69487fbc",
   "metadata": {},
   "source": [
    "### 22) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 130** from the X_test_std data. Make sure your print statement uses a complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The predicted probablity for belonging to the class[class=0 class=1] are{0}'.format(lr.predict_proba(X_test[129,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e424d56",
   "metadata": {},
   "source": [
    "### 23) TO DO:class-membership probability\n",
    "Predict the class membership probability by using the a row with **index = 200** from the X_test_std data. Make sure your print statement uses a\n",
    "complete sentence and be sure to compare your prediction with the correct answer using the corresponding row from the test set labels, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a255623",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The predicted probablity for belonging to the class[class=0 class=1] are{0}'.format(lr.predict_proba(X_test[199,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd8331",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Build Linear Support Vector Classifier Model </h2>\n",
    "\n",
    "### 24) TO DO:scikit-learn Linear Support Vector Classifier for this lab\n",
    "\n",
    "**Import and instantiate the Linear Support Vector Classifier Model in SciKit-Learn is in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4cd66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#instantiate the model and fit the data\n",
    "lsvc=LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d9ed8",
   "metadata": {},
   "source": [
    "### 25) TO DO: Train the model by calling the model's fit function\n",
    "Now that the model has been instantiated (created) it still needs to be trained (fitted) to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a87f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ab2c2",
   "metadata": {},
   "source": [
    "### 26) TO DO: Evaluate the Linear Suport Vector Classifier Model\n",
    "Use the test set to create the model's predictions. Name the prediction vector **y_pred** as in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f526f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set prediction: \n",
      " ['three' 'three' 'one' 'one' 'three' 'three' 'one' 'two' 'one' 'one' 'two'\n",
      " 'two' 'two' 'one' 'three' 'one' 'two' 'one' 'three' 'two' 'three' 'one'\n",
      " 'two' 'two' 'one' 'one' 'two' 'three' 'three' 'one' 'two' 'two' 'two'\n",
      " 'one' 'two' 'one' 'one' 'one' 'two' 'two' 'one' 'three' 'one' 'three'\n",
      " 'three' 'three' 'two' 'two' 'three' 'one' 'three' 'three' 'one' 'one'\n",
      " 'three' 'one' 'two' 'two' 'one' 'one' 'one' 'two' 'one' 'one' 'two' 'two'\n",
      " 'one' 'two' 'one' 'two' 'one' 'three' 'one' 'one' 'two' 'three' 'one'\n",
      " 'one' 'two' 'three' 'three' 'one' 'three' 'two' 'two' 'one' 'two' 'two'\n",
      " 'three' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'one' 'two' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'one' 'two' 'two' 'one' 'three' 'two' 'two'\n",
      " 'two' 'one' 'one' 'one' 'one' 'three' 'one' 'two' 'one' 'three' 'three'\n",
      " 'one' 'one' 'two' 'two' 'two' 'three' 'two' 'one' 'one' 'three' 'one'\n",
      " 'three' 'two' 'one' 'two' 'two' 'two' 'three' 'two' 'two' 'one' 'two'\n",
      " 'two' 'two' 'two' 'two' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'two' 'two' 'two' 'one' 'two' 'one' 'one' 'two' 'one' 'two' 'one' 'two'\n",
      " 'three' 'one' 'two' 'two' 'two' 'two' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'one' 'two' 'three' 'three' 'three' 'two' 'one' 'one' 'two' 'two' 'two'\n",
      " 'one' 'one' 'one' 'one' 'two' 'two' 'three' 'three' 'one' 'one' 'one'\n",
      " 'one' 'two' 'two' 'three' 'one' 'one' 'one' 'three' 'three' 'two' 'three'\n",
      " 'one' 'three' 'two' 'one' 'one' 'one' 'two' 'two' 'one' 'two' 'two'\n",
      " 'three' 'one' 'two' 'one' 'one' 'three' 'one' 'one' 'two' 'one' 'two'\n",
      " 'one' 'two' 'one' 'two' 'two' 'one' 'two' 'three' 'three' 'one' 'two'\n",
      " 'one' 'three' 'one' 'two' 'three' 'two' 'two' 'one' 'one' 'one' 'three'\n",
      " 'one' 'two' 'two' 'one' 'three' 'one' 'three' 'one' 'three' 'two' 'two'\n",
      " 'two' 'one' 'one' 'one' 'one' 'two' 'one' 'two' 'one' 'three' 'one'\n",
      " 'three' 'three' 'one' 'two' 'one' 'two' 'two' 'three' 'two' 'two' 'three'\n",
      " 'two' 'one' 'two' 'three' 'three' 'two' 'three' 'one' 'three' 'three'\n",
      " 'one' 'three' 'three' 'three' 'two' 'two' 'one' 'one' 'three' 'one' 'one'\n",
      " 'two' 'three' 'two' 'two' 'two' 'two' 'two' 'two' 'one' 'three' 'one'\n",
      " 'three' 'three' 'one' 'two' 'one' 'three' 'two' 'one' 'two' 'two' 'two'\n",
      " 'one' 'three' 'three' 'one' 'two' 'three' 'one' 'two' 'one' 'three' 'one'\n",
      " 'two' 'three' 'two' 'one' 'three' 'two' 'two' 'one' 'three' 'one' 'one'\n",
      " 'two' 'one' 'one' 'one' 'three' 'one' 'one' 'two' 'two' 'one' 'one']\n"
     ]
    }
   ],
   "source": [
    "y_pred = lsvc.predict(X_test)\n",
    "print(\"Test set prediction: \\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff42f54",
   "metadata": {},
   "source": [
    "### 27) TO DO: Evaluate the Linear Suport Vector Model's Performance\n",
    "Use SciKit Learn's built-in scoring method to evaluate the model's performance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7b037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# using the score method\n",
    "print(\"Test set score: {0:0.2f}\".format(lsvc.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a17514",
   "metadata": {},
   "source": [
    "### 28) TO DO: Using the Predict Method of the Linear Suport Vector Model\n",
    "Use SciKit Learn's built-in *predict method* to test the model's predictive performance for the first row of data in X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b29b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the first row of X_test_std is: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordan/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_class = lsvc.predict(X_test_std[0].reshape(1, -1))\n",
    "print(f\"The predicted class for the first row of X_test_std is: {predicted_class[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19885d8",
   "metadata": {},
   "source": [
    "### 29) TO DO:Print the number of misclassifications using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0464fd",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Confusion Matrix </h2>\n",
    "\n",
    "Supervised learner models are designed to classify, estimate, and/or predict future outcome. For some applications the desire is to build models showing consistently high predictive accuracy.\n",
    "\n",
    "### Classification Correctness:\n",
    "\n",
    "Classification correctness is best calculated by presenting previously unseen data in the form of a test set to the model being evaluated. Test\n",
    "set model accuracy can be summarized in a table known as a confusion matrix. To illustrate, let’s suppose we have three possible classes: C1,\n",
    "C2, and C3. A generic confusion matrix for the three class case is shown in Table 1.\n",
    "\n",
    "* Values along the main diagonal give the total number of correct classifications for each class.\n",
    "  * For example, a value of 15 for C11 means that 15 class C1 test set instances were correctly classified.\n",
    "* Values other than those on the main diagonal represent classification errors.\n",
    "    * To illustrate, suppose C12 has the value 4. This means that four class C1 instances were incorrectly classified as belonging to class C2. The following three rules may be helpful in analyzing the information in a confusion matrix:\n",
    "\n",
    "### Rules for the Three-Class Confusion Matrix\n",
    "* Rule 1. Values along the main diagonal represent correct classifications. For the matrix in Table 1,the value C11 represents the total number of class C1 instances correctly classified by the model. A similar statement can be made for the values C22 and C33.\n",
    "* Rule 2. Values in row Ci represent those instances that belong to class Ci. For example, with i = 2,the instances associated with cells C21, C22, and C23 are all actually members of C2. To find the total number of C2 instances incorrectly classified as members of another class, we compute the sum of C21 and C23.\n",
    "* Rule 3. Values found in column Ci indicate those instances that have been classified as members of Ci. With i = 2,the instances associated with cells C12, C22, and C32 have been classified as members of class C2.To find the total number of instances incorrectly classified as members of class C2, we compute the sum of C12 and C32\n",
    "\n",
    "### 30) TO DO: Compute the Confusion Matrix for the Linear Suport Vector Model\n",
    "\n",
    "Use SciKit Learn's metrics module to compute the model's confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09fbfe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred, labels=lsvc.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels= lsvc.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237faac",
   "metadata": {},
   "source": [
    "### 31)TO DO: Classification Correctness\n",
    "Based on the output of your confusion matrix, what was the total number of correct classifications of Substance 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29a6c",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "The total number of correct classifications of substance 2 was 137."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1bbf7d",
   "metadata": {},
   "source": [
    "### 32) TO DO: Compute the Classification report for Linear Suport Vector Model\n",
    "Use SciKit Learn's metrics module to compute the model's classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e79ab642",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (877787960.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[34], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(metrics.classification_report(y_test, y_pred)\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf59116",
   "metadata": {},
   "source": [
    "### 33) TO DO: Classification Report\n",
    "\n",
    "Based on the output of your classification report, out of all the times Substance 1 should have been predicted, what percentage of times was\n",
    "it correctly predicted?\n",
    "\n",
    "Which performance score did you use to evaluate the performance of the model(s) from the confusion matrix /classification report? (HINT: You\n",
    "may need to research the meaning and difference between precision, recall and f1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2161d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b2760c",
   "metadata": {},
   "source": [
    "<h2 style = \"text-align: left; color:green\"> Serialization </h2>\n",
    "\n",
    "<h3 style = \"text-align: left; color:purple\"> 34) TO DO: Model Persistence - Save/Load the trained classifier  </h3>\n",
    "\n",
    "To receive full credit for this part you must test the saved and re-loaded classifiers on an instance of “unknown” data and show that it correctly\n",
    "classifies the instance. It’s ok if you use an instance (sample) that is from the test set as the “unknown” data.\n",
    "\n",
    "<b style = \"text-align: left; color:purple\"> NOTE: Use either the Logistic Regression Model or the K-Nearest Neighbors Classifier for this part  </b>\n",
    "\n",
    "### Step1: Save the model\n",
    "\n",
    "**Pickle (serialize) and save the trained classifier to a folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a0d2067",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1591777548.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    saved_classifer = ###\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#assign classifer to serialize \n",
    "saved_classifer = \"\"\"Im guessing this is just a path name??? \"\"\"\n",
    "#serialization with Pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('classifer','pkl_objects')\n",
    "if not os.path.exsits(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(saved_classifer, open(os.path.join(dest, 'classifer.pkl'),'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0216f0",
   "metadata": {},
   "source": [
    "### Step 2: Load the saved model\n",
    "\n",
    "**Load the saved the trained classifier into memory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved data to the trained classifer into memory\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "os.chdir('classifer')\n",
    "classifer_reloaded = pickle.load(open(os.path.join('pkl_objects','classifer.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3e14e",
   "metadata": {},
   "source": [
    "### Step 3: Test the re-loaded model\n",
    "\n",
    "Use SciKit Learn's built-in predict method to test the re-loaded model on data from the row of data in X_test_std with index equal to six (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a73212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "def01941",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "<h3 style = \"text-align:left; color: red\">BONUS (15 pts)</h3>\n",
    "\n",
    "It is **your choice** to do the bonus or not. It can only add points to your total course grade. It wont't hurt your grade if you chose NOT to do it.\n",
    "BUT, if you are going to attempt it, do it in the cells below (add cells as necessary). Follow the instructions for the notebook cells layout exactly\n",
    "as indicated in the bonus document or you may not receive credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbb194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e244d771",
   "metadata": {},
   "source": [
    "<h3 style = \"text-align:center; color: red\">End of Project</h3>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
